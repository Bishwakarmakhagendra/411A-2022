# 411A: Itroduction to Natural Language Programming

# üìú Course Description

This course aims to cover cutting-edge deep learning methods for natural language processing. The topics include part-of-speech tagging, parsing, word embeddings/contextualized word embeddings, pre-training and fine-tuning, machine translation, question answering, summarization, and information extraction etc.

# ‚ôæÔ∏è¬†Learning Goals

1. Be able to describe key concepts, models and challenges in Natural Language Processing
2. Be able to describe, implement, and apply a variety of fundamental algorithms in Natural Language Processing
3. Be able to describe and evaluate more complex software systems for various Natural Language Processing tasks
4. Be able to describe current approaches, datasets and systems for various Natural Language Processing tasks

# üìö Textbook

- **Speech and Language Processing (3rd ed. draft)** 
- by Dan Jurafsky and James H. Martin
- [https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/)


# üóìÔ∏è¬†Course Schedule

### 1. Introduction

- What is NLP?
- How does NLP work?
- Why is NLP hard?

### 2. Tokenization and Morphology

- How do we identify words in text?
- Word frequencies and Zipf‚Äôs Law
- What is a word, really?
- What is the structure of words?
- How can we identify the structure of words?

### 3. Language Models (Intro to Probability Models for NLP)

- Language models define probability distributions over the strings in a language.
- N-gram models are the simplest and most common kind of language model.

### 4. Introduction to Classification for NLP

- What is classification?
- The Naive Bayes classifier
- Running & evaluating classification experiments
- Features for Sentiment analysis

### 5. Logistic Regression

- From generative to discriminative classifiers (Logistic Regression and Multinomial Regression)
- Learning Logistic Regression Models with (Stochastic) Gradient Descent

### 6. Vector Semantics and Word Embeddings

- Lexical Semantics and the Distributional Hypothesis
- Distributional similarities
- Word Embeddings

### 7. Introduction to Neural Networks

- What are neural nets?
- Neural n-gram models

### 8. Mid-term

### 9. Part-of-Speech Tagging

- What is POS tagging?
- English Parts of Speech
- Hidden Markov Models (Definition)

### 10. Deep NLP

- CNN
- RNN
- Transformers

### 11. Machine Translation

- Why is machine translation hard?
- Different approaches to machine translation
- Statistical Machine Translation

### 12. Discourse and Referring Expressions

- natural language understanding
- natural language generation

### 13. Information Extraction

- Sequence Labeling
- Named Entity Recognition
- Relation Extraction

### 14. Question Answering

- Question Processing
- Document and Passage Retrieval
- Answer Extraction

### 15.

### 16. Final
